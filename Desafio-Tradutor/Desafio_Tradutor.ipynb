{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAzvYYTP+0l28dxd2t20qK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrbisao/BOOTCAMP-DIO-AI102/blob/main/Desafio_Tradutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eiu-PBDNP7Fe",
        "outputId": "2a827ad8-ad73-4369-d585-f3d4914b2918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAT_URL: https://oai-dio-bootcamp-dev-eastuus-mrbisao.openai.azure.com/openai/deployments/o4-mini/chat/completions?api-version=2025-01-01-preview\n",
            "Teste curto: Olá mundo\n",
            "Traduzindo bloco 1/33 (800 chars)...\n",
            "Traduzindo bloco 2/33 (800 chars)...\n",
            "Traduzindo bloco 3/33 (800 chars)...\n",
            "[chunk vazio] finish_reason=length usage={'completion_tokens': 2048, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2048, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 219, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 2267}\n",
            "Traduzindo bloco 4/33 (800 chars)...\n",
            "Traduzindo bloco 5/33 (800 chars)...\n",
            "[chunk vazio] finish_reason=length usage={'completion_tokens': 2048, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2048, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 215, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 2263}\n",
            "Traduzindo bloco 6/33 (800 chars)...\n",
            "Traduzindo bloco 7/33 (800 chars)...\n",
            "Traduzindo bloco 8/33 (800 chars)...\n",
            "Traduzindo bloco 9/33 (800 chars)...\n",
            "Traduzindo bloco 10/33 (800 chars)...\n",
            "Traduzindo bloco 11/33 (800 chars)...\n",
            "Traduzindo bloco 12/33 (800 chars)...\n",
            "Traduzindo bloco 13/33 (800 chars)...\n",
            "Traduzindo bloco 14/33 (800 chars)...\n",
            "Traduzindo bloco 15/33 (800 chars)...\n",
            "Traduzindo bloco 16/33 (800 chars)...\n",
            "Traduzindo bloco 17/33 (800 chars)...\n",
            "Traduzindo bloco 18/33 (800 chars)...\n",
            "[chunk vazio] finish_reason=length usage={'completion_tokens': 2048, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2048, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 243, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 2291}\n",
            "Traduzindo bloco 19/33 (800 chars)...\n",
            "Traduzindo bloco 20/33 (800 chars)...\n",
            "Traduzindo bloco 21/33 (800 chars)...\n",
            "Traduzindo bloco 22/33 (800 chars)...\n",
            "Traduzindo bloco 23/33 (800 chars)...\n",
            "[chunk vazio] finish_reason=length usage={'completion_tokens': 2048, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2048, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 264, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 2312}\n",
            "Traduzindo bloco 24/33 (800 chars)...\n",
            "Traduzindo bloco 25/33 (800 chars)...\n",
            "Traduzindo bloco 26/33 (800 chars)...\n",
            "Traduzindo bloco 27/33 (800 chars)...\n",
            "Traduzindo bloco 28/33 (800 chars)...\n",
            "[chunk vazio] finish_reason=length usage={'completion_tokens': 2048, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2048, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 214, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 2262}\n",
            "Traduzindo bloco 29/33 (800 chars)...\n",
            "Traduzindo bloco 30/33 (800 chars)...\n",
            "[chunk vazio] finish_reason=length usage={'completion_tokens': 2048, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2048, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 213, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 2261}\n",
            "Traduzindo bloco 31/33 (800 chars)...\n",
            "Traduzindo bloco 32/33 (800 chars)...\n",
            "Traduzindo bloco 33/33 (710 chars)...\n",
            "[chunk vazio] finish_reason=length usage={'completion_tokens': 2048, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2048, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 199, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 2247}\n",
            "\n",
            "--- Início da tradução ---\n",
            "\n",
            "# Necessidade da Camada de Rede\n",
            "\n",
            "A camada de rede é essencial para resolver o problema de entrega de dados através de vários enlaces em uma internetwork. Ela garante a entrega de pacotes de host a host e gerencia o roteamento desses pacotes por diversos roteadores e switches, o que é crucial quando os dados precisam viajar por redes diferentes.\n",
            "\n",
            "Em uma internetwork, a camada de rede é responsável por assegurar que os pacotes criados pelo dispositivo de origem sejam transmitidos corretamente até o dispositivo de destino, mesmo que precisem passar por múltiplas redes intermediárias (por exemplo, LANs e WANs). Sem a camada de rede, os dispositivos não conseguiriam se comunicar além de sua rede local.\n",
            "\n",
            "## Camada de Rede na Origem, no Roteador e no Destino\n",
            "\n",
            "### Camada de Rede na Origem  \n",
            "A camada de rede no host de origem i\n",
            "\n",
            "É responsável por preparar um pacote a partir dos dados recebidos de outros protocolos (como a camada de transporte ou a camada de aplicação). Ele encapsula os dados em um pacote e adiciona as informações de roteamento necessárias, como o endereço IP de origem e o endereço IP de destino. O dispositivo de origem verifica sua tabela de roteamento para determinar para onde enviar o pacote a seguir. Se o pacote for muito grande, a camada de rede fragmentará o pacote em unidades menores para garantir que se encaixem no tamanho máximo permitido pela rede.\n",
            "\n",
            "Camada de Rede no Roteador:  \n",
            "Roteadores, que operam na camada de rede, recebem pacotes de entrada e consultam \n",
            "\n",
            "Arquivo salvo: artigo_traduzido.md\n"
          ]
        }
      ],
      "source": [
        "# =====================  Imports =====================\n",
        "from bs4 import BeautifulSoup\n",
        "import requests, os, time, json\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "load_dotenv(\"config.env\", override=True)\n",
        "\n",
        "AZURE_ENDPOINT   = os.getenv(\"AZURE_ENDPOINT\", \"\").rstrip(\"/\")\n",
        "AZURE_API_KEY    = os.getenv(\"AZURE_OPENAI_KEY\")\n",
        "AZURE_DEPLOYMENT = os.getenv(\"AZURE_DEPLOYMENT\", \"o4-mini\")\n",
        "AZURE_API_VER    = os.getenv(\"AZURE_API_VERSION\", \"2025-01-01-preview\")\n",
        "\n",
        "CHAT_URL = f\"{AZURE_ENDPOINT}/openai/deployments/{AZURE_DEPLOYMENT}/chat/completions?api-version={AZURE_API_VER}\"\n",
        "HEADERS  = {\"Content-Type\": \"application/json\", \"api-key\": AZURE_API_KEY}\n",
        "\n",
        "print(\"CHAT_URL:\", CHAT_URL)\n",
        "\n",
        "# =====================  Extração de texto =====================\n",
        "def extract_text(url: str) -> str | None:\n",
        "    r = requests.get(url, timeout=40)\n",
        "    if r.status_code != 200:\n",
        "        print(\"Falha ao buscar a URL. Código:\", r.status_code); return None\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "    for tag in soup([\"script\",\"style\",\"noscript\"]): tag.decompose()\n",
        "    for sel in (\"div.crayons-article__body\", \"div#article-body\", \"article\"):\n",
        "        node = soup.select_one(sel)\n",
        "        if node and node.get_text(strip=True):\n",
        "            return node.get_text(\" \", strip=True)\n",
        "    return soup.get_text(\" \", strip=True)\n",
        "\n",
        "# =====================  Utilitários =====================\n",
        "def remove_codefences(text: str) -> str:\n",
        "    if not text: return text\n",
        "    t = text.strip()\n",
        "    if t.startswith(\"```\"):\n",
        "        lines = t.splitlines()\n",
        "        if lines and lines[0].startswith(\"```\"): lines = lines[1:]\n",
        "        if lines and lines[-1].strip() == \"```\": lines = lines[:-1]\n",
        "        t = \"\\n\".join(lines).strip()\n",
        "    return t\n",
        "\n",
        "def call_chat_completions(text_chunk: str, lang: str, max_tokens: int):\n",
        "    # Prompt enxuto, pedindo para NÃO usar cercas de código e sem explicações\n",
        "    messages = [\n",
        "        {\"role\":\"system\",\"content\":\"Você é um tradutor profissional. Faça tradução direta e fiel. Não adicione comentários, nem explicações. Não use blocos de código (sem ```). Responda apenas com a tradução em Markdown simples.\"},\n",
        "        {\"role\":\"user\",\"content\":f\"Traduza para {lang} o texto abaixo, mantendo títulos e listas quando fizer sentido:\\n\\n{text_chunk}\"}\n",
        "    ]\n",
        "    payload = {\n",
        "        \"messages\": messages,\n",
        "        \"max_completion_tokens\": max_tokens,\n",
        "        \"temperature\": 1  # se seu deployment não aceitar, removemos no retry abaixo\n",
        "    }\n",
        "\n",
        "    r = requests.post(CHAT_URL, headers=HEADERS, json=payload, timeout=180)\n",
        "    try:\n",
        "        data = r.json()\n",
        "    except Exception:\n",
        "        raise SystemExit(f\"Status={r.status_code}\\nResposta bruta:\\n{r.text}\")\n",
        "\n",
        "    # retry automático se algum parâmetro for rejeitado\n",
        "    if r.status_code == 400 and isinstance(data, dict):\n",
        "        err = (data.get(\"error\") or {})\n",
        "        if err.get(\"code\") == \"unsupported_parameter\":\n",
        "            param = err.get(\"param\")\n",
        "            if param in payload:\n",
        "                payload.pop(param, None)\n",
        "                r = requests.post(CHAT_URL, headers=HEADERS, json=payload, timeout=180)\n",
        "                try:\n",
        "                    data = r.json()\n",
        "                except Exception:\n",
        "                    raise SystemExit(f\"[Retry] Status={r.status_code}\\nResposta bruta:\\n{r.text}\")\n",
        "\n",
        "    if r.status_code != 200:\n",
        "        raise SystemExit(f\"Erro {r.status_code}:\\n{json.dumps(data, ensure_ascii=False, indent=2)}\")\n",
        "\n",
        "    choice = (data.get(\"choices\") or [{}])[0]\n",
        "    content = ((choice.get(\"message\") or {}).get(\"content\") or \"\").strip()\n",
        "    finish  = choice.get(\"finish_reason\")\n",
        "    usage   = data.get(\"usage\", {})\n",
        "    return remove_codefences(content), finish, usage\n",
        "\n",
        "def translate_chunk_adaptativo(text_chunk: str, lang: str) -> str:\n",
        "    # 1) tenta com tokens maiores; se vier vazio/length, divide\n",
        "    for tok in (2048, 4096, 6144):\n",
        "        out, finish, usage = call_chat_completions(text_chunk, lang, tok)\n",
        "        if out:\n",
        "            return out\n",
        "        if finish == \"length\":\n",
        "            print(f\"[chunk vazio] finish_reason=length usage={usage}\")\n",
        "            continue\n",
        "    # 2) dividir em 2 sub-blocos se ainda vazio\n",
        "    if len(text_chunk) > 300:\n",
        "        mid = len(text_chunk)//2\n",
        "        left  = translate_chunk_adaptativo(text_chunk[:mid], lang)\n",
        "        right = translate_chunk_adaptativo(text_chunk[mid:], lang)\n",
        "        return (left + \"\\n\\n\" + right).strip()\n",
        "    # 3) último esforço com tokens menores (às vezes resolve)\n",
        "    out, _, _ = call_chat_completions(text_chunk, lang, 1024)\n",
        "    return out\n",
        "\n",
        "# ===================== 5) Tradução com chunking =====================\n",
        "def translate_article(full_text: str, lang: str, chunk_chars: int = 800) -> str:\n",
        "    if not full_text: return \"\"\n",
        "    parts = [full_text[i:i+chunk_chars] for i in range(0, len(full_text), chunk_chars)]\n",
        "    translated = []\n",
        "    for i, chunk in enumerate(parts, 1):\n",
        "        print(f\"Traduzindo bloco {i}/{len(parts)} ({len(chunk)} chars)...\")\n",
        "        t = translate_chunk_adaptativo(chunk, lang)\n",
        "        translated.append(t or \"\")\n",
        "        time.sleep(0.2)\n",
        "    return \"\\n\\n\".join(translated).strip()\n",
        "\n",
        "# ===================== 6) Uso =====================\n",
        "# sanity check\n",
        "print(\"Teste curto:\", translate_chunk_adaptativo(\"Hello world\", \"português\")[:120])\n",
        "\n",
        "# Artigo OSI\n",
        "url = \"https://dev.to/harshm03/network-layer-internet-protocol-computer-networks-4847\"\n",
        "text = extract_text(url)\n",
        "if text:\n",
        "    artigo_pt = translate_article(text, \"português\", chunk_chars=800)\n",
        "    print(\"\\n--- Início da tradução ---\\n\")\n",
        "    print(artigo_pt[:1500])\n",
        "\n",
        "    # salvar em arquivo .md\n",
        "    with open(\"artigo_traduzido.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(artigo_pt)\n",
        "    print(\"\\nArquivo salvo: artigo_traduzido.md\")\n",
        "else:\n",
        "    print(\"Não foi possível extrair texto da URL.\")\n"
      ]
    }
  ]
}
